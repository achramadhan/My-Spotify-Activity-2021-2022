---
title: "My Spotify Activity 2021 October-2022 November"
author: "Rama"
date: "2022-11-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This data set is taken from requesting data from Spotify (access your Spotify account dashboard at https://www.spotify.com/). In the privacy settings, you will find the option to request your data and confirm via email. For this process, the maximum data request is 30 days, but within 3 days, the data is ready for download, which is notified by email.
This analysis is a personal project to find out my activities as a Spotify application user for the past year. The data collected by Spotify is from October 31, 2021, to November 1, 2022.


## Prepare

```{r echo=TRUE, results='hide', message=FALSE, warning=FALSE, paged.print=FALSE}
library(dplyr)
library(tidyverse)
library(tidyr)
library(janitor)
library(ggplot2)
library(lubridate)
```

Because it uses a JSON file, it requires a JSON library to read the file.
```{r echo=TRUE, results='hide', message=FALSE, warning=FALSE, paged.print=FALSE}
library(rjson)
```

## Process
import the json file using functionn "fromJSON"
```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
result <- fromJSON(file= "MyData/StreamingHistory0.json")
result1 <- fromJSON(file= "MyData/StreamingHistory1.json")
result2 <- fromJSON(file= "MyData/StreamingHistory2.json")
head(result, 1)
```
Because the file is in the form of JSON, the data is in the form of a list. To convert it into a data frame, use the following command:

```{r  echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
history <- do.call(rbind.data.frame, result)
history1 <- do.call(rbind.data.frame, result1)
history2 <- do.call(rbind.data.frame, result2)
head(history)
```

Head command to view the top 6 data points from the "history" data frame. After the 3 data points are ready to be processed, the next step is to combine the 3 data frames into one using "bind.rows."
```{r}
streaming_history <- bind_rows(history, history1, history2)
colnames(streaming_history)
streaming_history <- clean_names(streaming_history)
head(streaming_history)
```
"clean_names()" to cleaning column names 


```{r}
streaming_history$end_time <- ymd_hm(streaming_history$end_time)
```
changing the data type "end_time" from "char" to "date time" using "ymd_hm"because the data consists of "year","month","day","hour","minutes"

## Analyze


```{r}
summary(streaming_history)
```
"summary" used to quick analyze the data,  "Min.:2021-10-31" is started date and ends on "Max.:2022-11-01"The data used is activity data from Spotify over the past year. column "ms_played" is the millisecond length of the stream of songs that have been listened to.


### Top 10 Listened by Track Name
```{r}
streaming_history %>% group_by(track_name) %>% 
  summarise(total_listened = n()) %>% 
  arrange(desc(total_listened)) %>% 
  slice(1:10)
```
The data above is the number of songs that are often listened to by song titles and sorted in descending order, which only shows the top 10; the top position is listened to by as many as 236 songs with the title "Feels Like That."

### Top 10 Listened by Artist Name
```{r}
streaming_history %>% group_by(artist_name) %>% 
  summarise(total_listened = n(),
            duration = dmilliseconds(sum(ms_played))) %>% 
  arrange(desc(total_listened)) %>% 
  slice(1:10)
```
The data above is the number of songs that are often listened to by artist name; the top position is "Jay Ham," as many as 1065, with a total number of streaming 160464.51 seconds, or 44.6 hours, or 1.86 days.

### Total Listened Songs by Hour
```{r}
streaming_history %>% mutate(hour = hour(end_time)) %>% 
  group_by(hour) %>% 
  summarise(total_listened = n()) %>%
  ggplot(aes(factor(hour), total_listened))+
  geom_bar(stat='identity', fill='orange')+
  geom_text(aes(label=total_listened),vjust=-0.7, size=3, angle = 30 )+
  xlab("hour")
```

During the year indicated, users listen more to songs at 6 a.m. and 7 a.m. in the morning, while during the day users listen to songs more at 13 p.m., 14 p.m., and 15 p.m.The time zone used is the Jakarta time zone. Most users listen to songs at 15 o clock, as many as 2126 songs

### Total Listened Songs By Month
```{r}
streaming_history %>% 
  mutate(month = factor(months(end_time), levels=month.name)) %>%
  group_by(month) %>%
  summarise(total_listened = n()) %>%
  arrange(month) %>% 
  ggplot(aes(month, total_listened))+
  geom_bar(stat = 'identity', fill ='orange')+
  theme(axis.text.x = element_text(angle=20))+
  geom_text(aes(label=total_listened),vjust=-0.7, size=3)+
  xlab("Month")
```

User activity by month showed that the highest was in May with a total of 3241 songs, while the lowest was in September with a total of 1009 songs. Users listen to more than 1000 songs every month, and it can be concluded that users are very active in listening to songs using the Spotify app.


### Top Listened Songs by Day of Week
```{r}
streaming_history %>% 
  mutate(day_of_week = factor(weekdays(end_time), levels=c("Sunday", "Monday", "Tuesday","Wednesday", "Thursday","Friday", "Saturday"))) %>%
  group_by(day_of_week) %>%
  summarise(total_listened = n()) %>%
  arrange(day_of_week) %>% 
  ggplot(aes(day_of_week, total_listened))+
  geom_bar(stat = 'identity', fill='orange')+
  geom_text(aes(label=total_listened),vjust=-0.7, size=3)+
  xlab("Day of Week")+ ylab("Total Listened")
```

User activity based on daily listening shows that the highest was on Monday with a total of 3584 songs listened to, while the lowest was on Wednesday with a total of 2720 songs listened to.



## Summary

- Users very often use the Spotify application; based on data for a year, monthly users listen to songs with a total of over 1000 songs.

- The highest user activity is in May, and the busiest day is Monday.

- The user's favorite artist is Jay Ham with 1065 total songs played.

- The user's favorite song is Feels Like That (Ashley Metha).